{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from goss import SimpleGOSS\n",
    "\n",
    "data = pd.read_csv(\"./data/boston.csv\")\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = SimpleGOSS(n_trees=70, learning_rate=0.1, a=0.2, b=0.4, max_depth=7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([395, 78, 346, 208, 229, 101, 316, 86, 381, 312])\n",
    "\n",
    "cnt = pd.Series(np.zeros(len(X_train)), dtype=int)\n",
    "# cnt[list(arr)] += 1\n",
    "cnt[arr] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[78, 86, 101, 208, 229, 312, 316, 346, 381, 395]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cnt[cnt > 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[395, 78, 346, 208, 229, 101, 316, 86, 381, 312]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([395, 78, 346, 208, 229, 101, 316, 86, 381, 312], dtype='int64')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cnt[[\u001b[39m395\u001b[39;49m, \u001b[39m78\u001b[39;49m, \u001b[39m346\u001b[39;49m, \u001b[39m208\u001b[39;49m, \u001b[39m229\u001b[39;49m, \u001b[39m101\u001b[39;49m, \u001b[39m316\u001b[39;49m, \u001b[39m86\u001b[39;49m, \u001b[39m381\u001b[39;49m, \u001b[39m312\u001b[39;49m]]\n",
      "File \u001b[0;32m~/workspace/math/venv/lib/python3.11/site-packages/pandas/core/series.py:1038\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1035\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m   1036\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_values(key)\n\u001b[0;32m-> 1038\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_with(key)\n",
      "File \u001b[0;32m~/workspace/math/venv/lib/python3.11/site-packages/pandas/core/series.py:1073\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[39mif\u001b[39;00m key_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minteger\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1070\u001b[0m     \u001b[39m# We need to decide whether to treat this as a positional indexer\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m     \u001b[39m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_should_fallback_to_positional:\n\u001b[0;32m-> 1073\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc[key]\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[key]\n",
      "File \u001b[0;32m~/workspace/math/venv/lib/python3.11/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/workspace/math/venv/lib/python3.11/site-packages/pandas/core/indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1330\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1334\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/workspace/math/venv/lib/python3.11/site-packages/pandas/core/indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1271\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1272\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1273\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/math/venv/lib/python3.11/site-packages/pandas/core/indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1459\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1460\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1462\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1464\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/workspace/math/venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5873\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5876\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5878\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5880\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/math/venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5933\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5934\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 5935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5937\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   5938\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([395, 78, 346, 208, 229, 101, 316, 86, 381, 312], dtype='int64')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "cnt[[395, 78, 346, 208, 229, 101, 316, 86, 381, 312]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<goss.SimpleGOSS at 0x121074c50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>8.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>349.48</td>\n",
       "      <td>24.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>3.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03466</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>6.031</td>\n",
       "      <td>23.3</td>\n",
       "      <td>6.6407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>362.25</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.05042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>6.103</td>\n",
       "      <td>85.1</td>\n",
       "      <td>2.0218</td>\n",
       "      <td>8.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>2.52</td>\n",
       "      <td>23.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>3.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>5.836</td>\n",
       "      <td>91.9</td>\n",
       "      <td>2.2110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>395.67</td>\n",
       "      <td>18.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.29916</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>5.856</td>\n",
       "      <td>42.1</td>\n",
       "      <td>4.4290</td>\n",
       "      <td>2.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>388.65</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.01501</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>6.635</td>\n",
       "      <td>29.7</td>\n",
       "      <td>8.3440</td>\n",
       "      <td>3.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>390.94</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>11.16040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>6.629</td>\n",
       "      <td>94.6</td>\n",
       "      <td>2.1247</td>\n",
       "      <td>8.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>109.85</td>\n",
       "      <td>23.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.22876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>6.405</td>\n",
       "      <td>85.4</td>\n",
       "      <td>2.7147</td>\n",
       "      <td>4.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>70.80</td>\n",
       "      <td>10.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN  INDUS  CHAS     NOX     RM   AGE     DIS  RAD    TAX   \n",
       "0    15.02340   0.0  18.10   0.0  0.6140  5.304  97.3  2.1007  8.0  666.0  \\\n",
       "1     0.62739   0.0   8.14   0.0  0.5380  5.834  56.5  4.4986  3.0  307.0   \n",
       "2     0.03466  35.0   6.06   0.0  0.4379  6.031  23.3  6.6407  0.0  304.0   \n",
       "3     7.05042   0.0  18.10   0.0  0.6140  6.103  85.1  2.0218  8.0  666.0   \n",
       "4     0.72580   0.0   8.14   0.0  0.5380  5.727  69.5  3.7965  3.0  307.0   \n",
       "..        ...   ...    ...   ...     ...    ...   ...     ...  ...    ...   \n",
       "399   0.17120   0.0   8.56   0.0  0.5200  5.836  91.9  2.2110  4.0  384.0   \n",
       "400   0.29916  20.0   6.96   0.0  0.4640  5.856  42.1  4.4290  2.0  223.0   \n",
       "401   0.01501  80.0   2.01   0.0  0.4350  6.635  29.7  8.3440  3.0  280.0   \n",
       "402  11.16040   0.0  18.10   0.0  0.7400  6.629  94.6  2.1247  8.0  666.0   \n",
       "403   0.22876   0.0   8.56   0.0  0.5200  6.405  85.4  2.7147  4.0  384.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       20.2  349.48  24.91  \n",
       "1       21.0  395.62   8.47  \n",
       "2       16.9  362.25   7.83  \n",
       "3       20.2    2.52  23.29  \n",
       "4       21.0  390.95  11.28  \n",
       "..       ...     ...    ...  \n",
       "399     20.9  395.67  18.66  \n",
       "400     18.6  388.65  13.00  \n",
       "401     17.0  390.94   5.99  \n",
       "402     20.2  109.85  23.27  \n",
       "403     20.9   70.80  10.63  \n",
       "\n",
       "[404 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.2\n",
    "b = 0.4\n",
    "a + (1 - a) * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# よく使われたデータは、それだけ残差（勾配）が大きく、まだ十分な学習が行われていなかったということ\n",
    "# つまり、残差がなかなか減らず、予測が難しいデータポイントであったということ（境界付近のデータかあるいは外れ値か）\n",
    "model.used_cnt.sort_values(ascending=False).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_boston_dataset():\n",
    "    data = fetch_openml(name='Boston', version=1, as_frame=False)\n",
    "    X, y = data.data, data.target\n",
    "    features = data.feature_names\n",
    "    return X, y, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, feats = load_boston_dataset()\n",
    "df = pd.DataFrame(X, columns=feats)\n",
    "df['target'] = y\n",
    "\n",
    "df.to_csv('boston.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGOSS:\n",
    "    def __init__(self, n_trees=100, learning_rate=0.01, a=0.2, b=0.1, max_depth=4):\n",
    "        self.n_trees = n_trees\n",
    "        self.learning_rate = learning_rate\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        self.costs = []\n",
    "\n",
    "    # MSE\n",
    "    def _calc_cost(self, y, y_pred):\n",
    "        return np.mean((y - y_pred) ** 2)\n",
    "\n",
    "    # MSEの負の勾配\n",
    "    # MSEの勾配は: -2 * (y - y_pred) / len(y)\n",
    "    # MSEの負の勾配を使っても良いが、定数倍は勾配降下法の学習率で調整できるため、簡潔に残差を使う。\n",
    "    # ただし残差はMSEの負の勾配に比例するので、採用して問題ない。\n",
    "    def _calc_gradients(self, y, y_pred):\n",
    "        return y - y_pred\n",
    "        # return 2 * (y - y_pred) / len(y)\n",
    "\n",
    "    def _goss_sampling(self, X, top_n, rand_n, grads):\n",
    "        top_indices = np.argpartition(np.abs(grads), -top_n)[-top_n:]\n",
    "        rand_indices = np.setdiff1d(np.arange(len(X)), top_indices)\n",
    "        # 論文に忠実な実装\n",
    "        # rand_indices = np.random.choice(np.setdiff1d(np.arange(len(X)), top_indices), size=rand_n, replace=False)\n",
    "        # こっちの方が精度が出る\n",
    "        print(f\"top_indices: {top_indices}, rand_indices: {rand_indices}\")\n",
    "        rand_indices = np.random.choice(rand_indices, size=rand_n, replace=False, p=np.abs(grads[rand_indices]) / np.abs(grads[rand_indices]).sum())\n",
    "        used_indices = np.concatenate([top_indices, rand_indices])\n",
    "        return used_indices\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # X = np.array(X)\n",
    "        # y = np.array(y)\n",
    "        np.random.seed(42)\n",
    "\n",
    "        self.F0 = y.mean()\n",
    "        Fm = np.repeat(self.F0, X.shape[0])\n",
    "\n",
    "        top_n = int(self.a * len(X))\n",
    "        rand_n = int(self.b * len(X))\n",
    "\n",
    "        for _ in range(self.n_trees):\n",
    "            grads = self._calc_gradients(y, Fm)\n",
    "\n",
    "            used_indices = self._goss_sampling(X, top_n, rand_n, grads)\n",
    "\n",
    "            # 重みを計算\n",
    "            # ランダムサンプリングしたデータに重みをつける\n",
    "            # 論文に忠実な実装\n",
    "            # top_wight = np.repeat(self.a / top_n, top_n)\n",
    "            # rand_weight = np.repeat((1 - self.a) / self.b, rand_n)\n",
    "            # weight = np.concatenate([top_wight, rand_weight])\n",
    "            # こっちの方が精度が出る\n",
    "            weight = np.abs(grads[used_indices])\n",
    "\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, random_state=42)\n",
    "            tree.fit(X[used_indices], grads[used_indices], sample_weight=weight)\n",
    "\n",
    "            self.costs.append(self._calc_cost(y[used_indices], Fm[used_indices]))\n",
    "\n",
    "            # Fmを更新\n",
    "            Fm += self.learning_rate * tree.predict(X)\n",
    "\n",
    "            self.trees.append(tree)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        Fm = np.repeat(self.F0, X.shape[0])\n",
    "        pred = Fm + self.learning_rate * np.sum([tree.predict(X) for tree in self.trees], axis=0)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "X, y = load_boston_dataset()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params = {'n_trees': [50, 70, 100, 150, 200, 300], 'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1], 'a': [0.1, 0.2, 0.3, 0.4], 'b': [0.1, 0.2, 0.3, 0.4], 'max_depth': list(np.arange(3, 10))}\n",
    "grid = ParameterGrid(params)\n",
    "\n",
    "best_score = 10000\n",
    "best_param = None\n",
    "\n",
    "total = len(grid)\n",
    "for i, param in enumerate(grid):\n",
    "    print(f'{i+1}/{total}')\n",
    "    model = SimpleGOSS(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_param = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_score)\n",
    "print(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = load_boston_dataset()\n",
    "data = pd.read_csv(\"boston.csv\")\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "goss = SimpleGOSS(n_trees=70, learning_rate=0.1, a=0.2, b=0.4, max_depth=7)\n",
    "goss.fit(X_train, y_train)\n",
    "y_pred_train = goss.predict(X_train)\n",
    "y_pred_test = goss.predict(X_test)\n",
    "\n",
    "print(f\"Train error: {mean_squared_error(y_train, y_pred_train):.2f}\")\n",
    "print(f\"Test error: {mean_squared_error(y_test, y_pred_test):.2f}\")\n",
    "\n",
    "plt.plot(goss.costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=5)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_train = tree.predict(X_train)\n",
    "y_pred_test = tree.predict(X_test)\n",
    "print(f\"Train error: {mean_squared_error(y_train, y_pred_train):.2f}\")\n",
    "print(f\"Test error: {mean_squared_error(y_test, y_pred_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBDT:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        self.costs = []\n",
    "    \n",
    "    def _calc_cost(self, y, y_pred):\n",
    "        return np.mean(np.abs(y - y_pred))\n",
    "    \n",
    "    def _calc_gradients(self, y, y_pred):\n",
    "        return y - y_pred\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.F0 = y.mean()\n",
    "        Fm = np.repeat(self.F0, y.shape[0])\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            # 残差を計算\n",
    "            grads = self._calc_gradients(y, Fm)\n",
    "            self.costs.append(self._calc_cost(y, Fm))\n",
    "\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, random_state=42)\n",
    "            tree.fit(X, grads)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            Fm += self.learning_rate * tree.predict(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        Fm = np.repeat(self.F0, X.shape[0])\n",
    "        pred = Fm + self.learning_rate * np.sum([tree.predict(X) for tree in self.trees], axis=0)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = GBDT(max_depth=6)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_train = tree.predict(X_train)\n",
    "y_pred_test = tree.predict(X_test)\n",
    "print(f\"Train error: {mean_squared_error(y_train, y_pred_train):.2f}\")\n",
    "print(f\"Test error: {mean_squared_error(y_test, y_pred_test):.2f}\")\n",
    "\n",
    "plt.plot(tree.costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGOSS:\n",
    "    def __init__(self, n_trees=100, learning_rate=0.01, a=0.2, b=0.1, max_depth=4):\n",
    "        self.n_trees = n_trees\n",
    "        self.learning_rate = learning_rate\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        self.costs = []\n",
    "\n",
    "    # MSE\n",
    "    def _calc_cost(self, y, y_pred):\n",
    "        return np.mean((y - y_pred) ** 2)\n",
    "\n",
    "    def _calc_gradients(self, y, y_pred):\n",
    "        return y - y_pred\n",
    "        # return 2 * (y - y_pred) / len(y)\n",
    "\n",
    "    def _goss_sampling(self, X, top_n, rand_n, grads):\n",
    "        print(grads)\n",
    "        top_indices = np.argpartition(np.abs(grads), -top_n)[-top_n:]\n",
    "        rand_indices = np.setdiff1d(np.arange(len(X)), top_indices)\n",
    "        # print(f\"rand_indices: {len(rand_indices)}, rand_n: {rand_n}\")\n",
    "        rand_indices = np.random.choice(rand_indices, size=rand_n, replace=False)\n",
    "        used_indices = np.concatenate([top_indices, rand_indices])\n",
    "        return used_indices\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # X = np.array(X)\n",
    "        # y = np.array(y)\n",
    "        np.random.seed(42)\n",
    "\n",
    "        self.F0 = y.mean()\n",
    "        Fm = np.repeat(self.F0, X.shape[0])\n",
    "\n",
    "        top_n = int(self.a * len(X))\n",
    "        rand_n = int(self.b * len(X))\n",
    "\n",
    "        for _ in range(self.n_trees):\n",
    "            grads = self._calc_gradients(y, Fm)\n",
    "            print(\"=\"*30)\n",
    "            print(grads)\n",
    "            print(\"=\"*30)\n",
    "            used_indices = self._goss_sampling(X, top_n, rand_n, grads)\n",
    "            weight = np.abs(grads[used_indices])\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, random_state=42)\n",
    "            tree.fit(X[used_indices], grads[used_indices], sample_weight=weight)\n",
    "            self.costs.append(self._calc_cost(y[used_indices], Fm[used_indices]))\n",
    "            Fm += self.learning_rate * tree.predict(X)\n",
    "            self.trees.append(tree)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # X = np.array(X)\n",
    "        Fm = np.repeat(self.F0, X.shape[0])\n",
    "        pred = Fm + self.learning_rate * np.sum([tree.predict(X) for tree in self.trees], axis=0)\n",
    "        return pred\n",
    "\n",
    "# X, y = load_boston_dataset()\n",
    "data = pd.read_csv(\"boston.csv\")\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "goss = SimpleGOSS(n_trees=70, learning_rate=0.1, a=0.2, b=0.4, max_depth=7)\n",
    "goss.fit(X_train, y_train)\n",
    "y_pred_train = goss.predict(X_train)\n",
    "y_pred_test = goss.predict(X_test)\n",
    "\n",
    "print(f\"Train error: {mean_squared_error(y_train, y_pred_train):.2f}\")\n",
    "print(f\"Test error: {mean_squared_error(y_test, y_pred_test):.2f}\")\n",
    "\n",
    "plt.plot(goss.costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F0 = y.mean()\n",
    "Fm = np.repeat(F0, X.shape[0])\n",
    "\n",
    "y - Fm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
